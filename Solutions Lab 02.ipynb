{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# üöÄ PyTorch Fundamentals: A Discovery Journey with MNIST\n",
    "\n",
    "##**Instructor: Andrea Ramirez-Salgado, PhD.**\n",
    "\n",
    "## Welcome, Deep Learning Explorer!\n",
    "\n",
    "You're about to embark on a hands-on journey where you'll discover the fundamental building blocks of modern deep learning. This isn't just about following instructions‚Äîit's about **exploring, experimenting, and understanding**.\n",
    "\n",
    "### üéØ What You'll Discover\n",
    "\n",
    "By the end of this lab, you'll have built intuition for:\n",
    "- **Tensors**: The DNA of deep learning\n",
    "- **Autograd**: The magic behind automatic differentiation\n",
    "- **Neural Networks**: From random weights to intelligent digit recognition\n",
    "- **Optimization**: How machines learn from data\n",
    "\n",
    "### üß™ Your Lab Philosophy\n",
    "\n",
    "This lab is designed around three principles:\n",
    "1. **Experiment First**: Try things, make mistakes, learn from them\n",
    "2. **Visualize Everything**: See what's happening under the hood\n",
    "3. **Connect Concepts**: Understand the \"why\" behind the \"what\"\n",
    "\n",
    "### üìä Your Progress Tracker\n",
    "\n",
    "Throughout this lab, you'll complete:\n",
    "- üîµ **Discovery Tasks**: Explore and experiment\n",
    "- üü¢ **Implementation Tasks**: Build real components\n",
    "- üü° **Reflection Tasks**: Deepen understanding\n",
    "- üî¥ **Challenge Tasks**: Push your boundaries\n",
    "\n",
    "**Pro Tip**: Don't rush! The goal is understanding, not completion speed.\n",
    "\n",
    "---\n",
    "\n",
    "Let's begin! üéì"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Setup: Your Deep Learning Toolkit\n",
    "\n",
    "### Installation Recommendation\n",
    "If you haven't already, create a dedicated conda environment for this class:\n",
    "\n",
    "```bash\n",
    "conda create -n deep-learning python=3.9\n",
    "conda activate deep-learning\n",
    "conda install pytorch torchvision -c pytorch\n",
    "conda install matplotlib numpy jupyter\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"‚úÖ PyTorch version: {torch.__version__}\")\n",
    "print(f\"‚úÖ GPU available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   Device: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "print(\"\\nüéâ You're all set! Let's dive in!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1_intro",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Tensor Mastery üßä\n",
    "\n",
    "## Why Tensors Matter\n",
    "\n",
    "Imagine you're organizing data in the real world:\n",
    "- A **number** (like temperature): scalar (0D)\n",
    "- A **list** (like daily temperatures): vector (1D)\n",
    "- A **spreadsheet** (like temperature across cities): matrix (2D)\n",
    "- A **video** (frames √ó height √ó width √ó color): 4D tensor\n",
    "\n",
    "Tensors are PyTorch's way of organizing data at any dimension. They're like NumPy arrays, but with superpowers:\n",
    "- üöÄ GPU acceleration\n",
    "- üßÆ Automatic differentiation\n",
    "- üìä Seamless integration with neural networks\n",
    "\n",
    "Let's discover these powers!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discovery_1",
   "metadata": {},
   "source": [
    "## üîµ Discovery 1: The Shape of Data\n",
    "\n",
    "### 1.1 Scalars - Single Numbers\n",
    "\n",
    "Think of a scalar as a single measurement: temperature, price, score, etc.\n",
    "\n",
    "**Your Mission**: Create a scalar tensor representing your favorite number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîµ TASK 1: Create a scalar tensor with your favorite number\n",
    "# Hint: Use torch.tensor()\n",
    "\n",
    "favorite_number = None  # Replace with your code\n",
    "\n",
    "# Let's inspect it!\n",
    "print(f\"Value: {favorite_number}\")\n",
    "print(f\"Shape: {favorite_number.shape}\")\n",
    "print(f\"Dimensions: {favorite_number.dim()}\")\n",
    "print(f\"Data type: {favorite_number.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection1",
   "metadata": {},
   "source": [
    "### üü° Reflection 1: When would you use scalar tensors?\n",
    "\n",
    "Think about training neural networks. What scalar values might you track?\n",
    "\n",
    "**Write your answer below** (double-click to edit):\n",
    "\n",
    "**Scalar tensors (0-dimensional tensors) are crucial for representing single values that summarize complex data or model states. In Deep Learning, we primarily use them to track:**\n",
    "\n",
    "1. **Performance Metrics**: \n",
    "   - **Loss**: The most common scalar! (e.g., `2.341` -> `0.102`). We plot this to verify the model is learning.\n",
    "   - **Accuracy**: A single percentage (e.g., `95.5%`) indicating how often the model is correct.\n",
    "\n",
    "2. **Hyperparameters & Control**:\n",
    "   - **Learning Rate**: This might change during training (decay), so we track it as a scalar.\n",
    "   - **Regularization penalties**: The value of L1/L2 terms added to the loss.\n",
    "\n",
    "3. **Diagnostics**:\n",
    "   - **Gradient Norm**: A scalar representing the magnitude of all gradients combined (helps detect exploding gradients).\n",
    "   - **Average Weight**: To check if weights are vanishing or exploding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discovery_2",
   "metadata": {},
   "source": [
    "### 1.2 Vectors - Sequences of Numbers\n",
    "\n",
    "Vectors are everywhere in deep learning:\n",
    "- Word embeddings (e.g., \"cat\" ‚Üí [0.2, 0.5, ..., 0.3])\n",
    "- Feature vectors (e.g., person's attributes)\n",
    "- Time series (e.g., stock prices over days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîµ TASK 2: Create a vector representing the number of hours you spent \n",
    "# on different activities yesterday (sleep, study, exercise, leisure, etc.)\n",
    "\n",
    "# We use a list [...] to create a vector (1D tensor)\n",
    "my_day = torch.tensor([8.0, 6.0, 1.5, 4.5, 4.0]) \n",
    "\n",
    "print(f\"My day: {my_day}\")\n",
    "print(f\"Shape: {my_day.shape}\")\n",
    "print(f\"Total hours: {my_day.sum().item()}\")\n",
    "\n",
    "# üîµ CHALLENGE: What's the average time per activity?\n",
    "average_time = my_day.mean()  # Calculate mean\n",
    "print(f\"Average time per activity: {average_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Let's visualize your day!\n",
    "if my_day is not None:\n",
    "    activities = ['Sleep', 'Study', 'Exercise', 'Leisure', 'Other']\n",
    "    activities = activities[:len(my_day)]  # Adjust to your vector length\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(activities, my_day.numpy())\n",
    "    plt.ylabel('Hours')\n",
    "    plt.title('How I Spent My Day')\n",
    "    plt.axhline(y=24/len(my_day), color='r', linestyle='--', label='Equal distribution')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection2",
   "metadata": {},
   "source": [
    "### üü° Reflection 2: Vector Use Cases\n",
    "\n",
    "In deep learning, you'll work with vectors constantly. List 3 examples of what vectors might represent:\n",
    "\n",
    "*Your answers:*\n",
    "1. \n",
    "2. \n",
    "3. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discovery_3",
   "metadata": {},
   "source": [
    "### 1.3 Matrices - Tables of Data\n",
    "\n",
    "Matrices are 2D tensors that store tabular data:\n",
    "- Images (grayscale): height √ó width\n",
    "- Weight matrices in neural networks\n",
    "- Batch of feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîµ TASK 3: Create a \"student grade\" matrix\n",
    "# Rows = students, Columns = assignments\n",
    "# Create a 4√ó5 matrix (4 students, 5 assignments) with random grades (0-100)\n",
    "\n",
    "# Hint: Use torch.randint(low, high, size)\n",
    "# We cast to .float() because .mean() requires floating point numbers\n",
    "grades = torch.randint(0, 101, (4, 5)).float()\n",
    "\n",
    "print(\"Grade Matrix:\")\n",
    "print(grades)\n",
    "print(f\"\\nShape: {grades.shape}\")\n",
    "\n",
    "# üîµ TASK 3b: Calculate each student's average grade\n",
    "# Collapse columns (dim=1) to get one average per student\n",
    "student_averages = grades.mean(dim=1) \n",
    "\n",
    "# üîµ TASK 3c: Calculate each assignment's average grade\n",
    "# Collapse rows (dim=0) to get one average per assignment\n",
    "assignment_averages = grades.mean(dim=0)\n",
    "\n",
    "print(f\"\\nStudent averages: {student_averages}\")\n",
    "print(f\"Assignment averages: {assignment_averages}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimension_exploration",
   "metadata": {},
   "source": [
    "### üß™ Experiment: Understanding Dimensions\n",
    "\n",
    "When you use `.mean(dim=0)` vs `.mean(dim=1)`, what happens?\n",
    "\n",
    "Run the code below and observe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dim_experiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a simple 3√ó4 matrix\n",
    "matrix = torch.tensor([\n",
    "    [1, 2, 3, 4],\n",
    "    [5, 6, 7, 8],\n",
    "    [9, 10, 11, 12]\n",
    "])\n",
    "\n",
    "print(\"Original matrix:\")\n",
    "print(matrix)\n",
    "print(f\"Shape: {matrix.shape}\\n\")\n",
    "\n",
    "print(\"Mean along dim=0 (collapse rows):\")\n",
    "print(matrix.mean(dim=0))\n",
    "print(f\"Shape: {matrix.mean(dim=0).shape}\\n\")\n",
    "\n",
    "print(\"Mean along dim=1 (collapse columns):\")\n",
    "print(matrix.mean(dim=1))\n",
    "print(f\"Shape: {matrix.mean(dim=1).shape}\")\n",
    "\n",
    "# üü° REFLECTION: In your own words, explain what dim=0 vs dim=1 does"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection3",
   "metadata": {},
   "source": [
    "### üü° Reflection 3: Your Explanation\n",
    "\n",
    "Explain in your own words:\n",
    "- What does `dim=0` do?\n",
    "- What does `dim=1` do?\n",
    "- Why does the output shape change?\n",
    "\n",
    "*Your explanation:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discovery_4",
   "metadata": {},
   "source": [
    "### 1.4 Higher-Dimensional Tensors - The Real World\n",
    "\n",
    "In deep learning, you'll often work with 4D tensors, especially for images:\n",
    "\n",
    "**Shape**: `(Batch, Channels, Height, Width)`\n",
    "\n",
    "For example, 32 RGB images of size 224√ó224:\n",
    "- Batch: 32 (number of images)\n",
    "- Channels: 3 (Red, Green, Blue)\n",
    "- Height: 224 pixels\n",
    "- Width: 224 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîµ TASK 4: Create a batch of grayscale images\n",
    "# Create a 4D tensor of zeros with shape (8, 1, 28, 28)\n",
    "# This represents 8 grayscale MNIST-like images\n",
    "\n",
    "image_batch = None  # Your code here (use torch.zeros)\n",
    "\n",
    "print(f\"Batch shape: {image_batch.shape}\")\n",
    "print(f\"Number of images: {image_batch.shape[0]}\")\n",
    "print(f\"Channels per image: {image_batch.shape[1]}\")\n",
    "print(f\"Image dimensions: {image_batch.shape[2]} √ó {image_batch.shape[3]}\")\n",
    "\n",
    "# üîµ TASK 4b: What's the total number of pixels in this batch?\n",
    "total_pixels = None  # Calculate this\n",
    "print(f\"\\nTotal pixels in batch: {total_pixels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tensor_ops",
   "metadata": {},
   "source": [
    "## üßÆ Tensor Operations: The Building Blocks\n",
    "\n",
    "Now let's explore the operations that power neural networks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ops_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic operations demonstration\n",
    "a = torch.tensor([1.0, 2.0, 3.0])\n",
    "b = torch.tensor([4.0, 5.0, 6.0])\n",
    "\n",
    "print(\"Vector a:\", a)\n",
    "print(\"Vector b:\", b)\n",
    "print(\"\\nOperations:\")\n",
    "print(f\"Addition (a + b): {a + b}\")\n",
    "print(f\"Element-wise multiplication (a * b): {a * b}\")\n",
    "print(f\"Dot product (a @ b): {a @ b}\")\n",
    "print(f\"Sum of a: {a.sum()}\")\n",
    "print(f\"Mean of a: {a.mean()}\")\n",
    "print(f\"Max of a: {a.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matrix_mult_discovery",
   "metadata": {},
   "source": [
    "### üî¥ Challenge 1: Matrix Multiplication Mystery\n",
    "\n",
    "Matrix multiplication is at the heart of neural networks. Let's discover why!\n",
    "\n",
    "**Your Mission**: \n",
    "1. Create a 3√ó4 matrix `W` (think of it as network weights)\n",
    "2. Create a 4√ó1 matrix `x` (think of it as input features)\n",
    "3. Multiply them: `output = W @ x`\n",
    "4. What's the shape of the output? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenge1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¥ CHALLENGE 1: Matrix multiplication\n",
    "\n",
    "W = torch.randn(3, 4)  # Random weights\n",
    "x = torch.randn(4, 1)  # Random input\n",
    "\n",
    "print(\"Weight matrix W shape:\", W.shape)\n",
    "print(\"Input vector x shape:\", x.shape)\n",
    "\n",
    "# Perform matrix multiplication\n",
    "output = None  # Your code: W @ x\n",
    "\n",
    "print(f\"\\nOutput shape: {output.shape}\")\n",
    "\n",
    "# üü° REFLECTION: Why is the output shape what it is?\n",
    "# What does each dimension represent in a neural network context?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection4",
   "metadata": {},
   "source": [
    "### üü° Reflection 4: Matrix Multiplication in Neural Networks\n",
    "\n",
    "Based on the experiment above:\n",
    "1. If `W` has shape (3, 4) and `x` has shape (4, 1), why is the output shape (3, 1)?\n",
    "2. What would this represent in a neural network? (Hint: think about layers)\n",
    "\n",
    "*Your explanation:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reshaping",
   "metadata": {},
   "source": [
    "### üîß Reshaping: Changing Perspectives\n",
    "\n",
    "Neural networks often need to reshape data. Let's master this critical skill!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reshape_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple image: 1√ó28√ó28 (1 channel, 28√ó28 pixels)\n",
    "image = torch.randn(1, 28, 28)\n",
    "print(f\"Original image shape: {image.shape}\")\n",
    "print(f\"Total elements: {image.numel()}\")\n",
    "\n",
    "# Flatten to a vector (needed for fully connected layers)\n",
    "flattened = image.view(-1)  # -1 means \"infer this dimension\"\n",
    "print(f\"\\nFlattened shape: {flattened.shape}\")\n",
    "\n",
    "# Alternative flattening\n",
    "flattened2 = image.reshape(1, -1)  # Keep batch dimension\n",
    "print(f\"Flattened (keep batch) shape: {flattened2.shape}\")\n",
    "\n",
    "# Reconstruct\n",
    "reconstructed = flattened.view(1, 28, 28)\n",
    "print(f\"\\nReconstructed shape: {reconstructed.shape}\")\n",
    "print(f\"Same as original? {torch.equal(image, reconstructed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîµ TASK 5: Reshape a batch of images\n",
    "# You have a batch of 32 RGB images, each 64√ó64 pixels\n",
    "# Shape: (32, 3, 64, 64)\n",
    "\n",
    "batch = torch.randn(32, 3, 64, 64)\n",
    "print(f\"Original batch shape: {batch.shape}\")\n",
    "\n",
    "# Flatten each image while keeping the batch dimension\n",
    "# Target shape: (32, 3*64*64) = (32, 12288)\n",
    "flattened_batch = None  # Your code here\n",
    "\n",
    "print(f\"Flattened batch shape: {flattened_batch.shape}\")\n",
    "\n",
    "# üîµ Verify: Does the number of elements match?\n",
    "print(f\"\\nOriginal elements: {batch.numel()}\")\n",
    "print(f\"Flattened elements: {flattened_batch.numel()}\")\n",
    "print(f\"Match? {batch.numel() == flattened_batch.numel()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2_intro",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Autograd - The Magic of Automatic Differentiation ‚ú®\n",
    "\n",
    "## Why Autograd is Revolutionary\n",
    "\n",
    "Imagine you had to calculate derivatives by hand for a network with millions of parameters. Impossible, right?\n",
    "\n",
    "**Autograd** automatically tracks operations and computes gradients. This is what makes modern deep learning possible!\n",
    "\n",
    "Let's discover how it works through experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "autograd_simple",
   "metadata": {},
   "source": [
    "### üß™ Experiment 1: Simple Gradient\n",
    "\n",
    "Let's start with a simple function: $f(x) = x^2$\n",
    "\n",
    "We know the derivative is: $\\frac{df}{dx} = 2x$\n",
    "\n",
    "Let's see PyTorch compute it automatically!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "autograd_demo1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor and tell PyTorch to track operations on it\n",
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "print(f\"x = {x}\")\n",
    "print(f\"Tracking gradients? {x.requires_grad}\")\n",
    "\n",
    "# Define function: f(x) = x^2\n",
    "y = x ** 2\n",
    "print(f\"\\ny = x^2 = {y}\")\n",
    "\n",
    "# Compute gradient\n",
    "y.backward()  # This computes dy/dx\n",
    "\n",
    "print(f\"\\nGradient dy/dx = {x.grad}\")\n",
    "print(f\"Expected (2*x) = {2 * x.item()}\")\n",
    "print(f\"Match? {abs(x.grad.item() - 2*x.item()) < 1e-6}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "autograd_complex",
   "metadata": {},
   "source": [
    "### üß™ Experiment 2: More Complex Function\n",
    "\n",
    "Now let's try: $f(x) = 3x^2 + 2x + 1$\n",
    "\n",
    "Derivative: $\\frac{df}{dx} = 6x + 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîµ TASK 6: Compute gradient of f(x) = 3x^2 + 2x + 1\n",
    "\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "\n",
    "# Define the function\n",
    "y = None  # Your code: 3*x**2 + 2*x + 1\n",
    "\n",
    "# Compute gradient\n",
    "# Your code here\n",
    "\n",
    "print(f\"x = {x.item()}\")\n",
    "print(f\"y = {y.item()}\")\n",
    "print(f\"\\nGradient dy/dx = {x.grad.item()}\")\n",
    "print(f\"Expected (6*x + 2) = {6*x.item() + 2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gradient_descent_intro",
   "metadata": {},
   "source": [
    "### üéØ Discovering Gradient Descent\n",
    "\n",
    "Now comes the magic: **using gradients to optimize**!\n",
    "\n",
    "Imagine you want to find the minimum of $f(x) = (x - 3)^2$\n",
    "\n",
    "We know the minimum is at $x = 3$, but let's let gradient descent discover it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gd_visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîµ TASK 7: Implement gradient descent to find the minimum\n",
    "\n",
    "# Start far from the minimum\n",
    "x = torch.tensor(10.0, requires_grad=True)\n",
    "learning_rate = 0.1\n",
    "num_steps = 50\n",
    "\n",
    "# Track the journey\n",
    "x_history = []\n",
    "y_history = []\n",
    "\n",
    "for step in range(num_steps):\n",
    "    # Compute function value\n",
    "    y = (x - 3) ** 2\n",
    "    \n",
    "    # Store for visualization\n",
    "    x_history.append(x.item())\n",
    "    y_history.append(y.item())\n",
    "    \n",
    "    # Compute gradient\n",
    "    # YOUR CODE HERE (hint: y.backward())\n",
    "    \n",
    "    # Update x using gradient descent: x = x - learning_rate * gradient\n",
    "    with torch.no_grad():  # Don't track this operation\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "    \n",
    "    # Clear gradient for next iteration\n",
    "    x.grad.zero_()\n",
    "    \n",
    "    if step % 10 == 0:\n",
    "        print(f\"Step {step}: x = {x.item():.4f}, y = {y.item():.4f}\")\n",
    "\n",
    "print(f\"\\nFinal x = {x.item():.4f} (target: 3.0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gd_plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Visualize the optimization journey\n",
    "if len(x_history) > 0:\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Plot 1: Function and optimization path\n",
    "    plt.subplot(1, 2, 1)\n",
    "    x_range = np.linspace(0, 12, 100)\n",
    "    y_range = (x_range - 3) ** 2\n",
    "    plt.plot(x_range, y_range, 'b-', linewidth=2, label='f(x) = (x-3)¬≤')\n",
    "    plt.plot(x_history, y_history, 'ro-', markersize=4, linewidth=1, alpha=0.6, label='Optimization path')\n",
    "    plt.axvline(x=3, color='g', linestyle='--', label='True minimum')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('f(x)')\n",
    "    plt.title('Gradient Descent in Action')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Convergence\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(y_history, 'r-', linewidth=2)\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss Over Time')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection5",
   "metadata": {},
   "source": [
    "### üü° Reflection 5: Understanding Gradient Descent\n",
    "\n",
    "Based on the visualization above:\n",
    "1. How did x change over time? Was it gradual or sudden?\n",
    "2. What role does the learning rate play?\n",
    "3. What happens if you set learning_rate = 1.0? Try it!\n",
    "4. How is this related to training neural networks?\n",
    "\n",
    "*Your insights:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3_intro",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: Building Your First Neural Network üß†\n",
    "\n",
    "## The MNIST Challenge\n",
    "\n",
    "You're about to build a neural network that can recognize handwritten digits (0-9).\n",
    "\n",
    "This is the \"Hello World\" of deep learning, but it's a real accomplishment!\n",
    "\n",
    "### The Dataset: MNIST\n",
    "\n",
    "- **Training samples**: 60,000 handwritten digits\n",
    "- **Test samples**: 10,000 handwritten digits  \n",
    "- **Image size**: 28√ó28 pixels (grayscale)\n",
    "- **Classes**: 10 (digits 0-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_mnist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Normalize (mean, std of MNIST)\n",
    "])\n",
    "\n",
    "# Download and load training data\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Download and load test data\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Training samples: {len(train_dataset)}\")\n",
    "print(f\"‚úÖ Test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explore_mnist",
   "metadata": {},
   "source": [
    "### üîç Exploring the Data\n",
    "\n",
    "Before building a model, let's understand what we're working with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz_mnist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Visualize random samples from the dataset\n",
    "\n",
    "fig, axes = plt.subplots(3, 6, figsize=(12, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(18):\n",
    "    # Get a random sample\n",
    "    idx = np.random.randint(len(train_dataset))\n",
    "    image, label = train_dataset[idx]\n",
    "    \n",
    "    # Convert from tensor to numpy for plotting\n",
    "    image = image.squeeze().numpy()\n",
    "    \n",
    "    axes[i].imshow(image, cmap='gray')\n",
    "    axes[i].set_title(f'Label: {label}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Random MNIST Samples', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Get a single image to inspect\n",
    "sample_image, sample_label = train_dataset[0]\n",
    "print(f\"\\nImage shape: {sample_image.shape}\")\n",
    "print(f\"Label: {sample_label}\")\n",
    "print(f\"Pixel value range: [{sample_image.min():.2f}, {sample_image.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "task8",
   "metadata": {},
   "source": [
    "### üîµ Task 8: Dataset Analysis\n",
    "\n",
    "Let's analyze the dataset distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze_dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many examples of each digit we have\n",
    "digit_counts = torch.zeros(10)\n",
    "\n",
    "for _, label in train_dataset:\n",
    "    digit_counts[label] += 1\n",
    "\n",
    "# üìä Visualize the distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(10), digit_counts.numpy())\n",
    "plt.xlabel('Digit')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Digits in Training Set')\n",
    "plt.xticks(range(10))\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"Count per digit:\")\n",
    "for digit in range(10):\n",
    "    print(f\"Digit {digit}: {int(digit_counts[digit])} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection6",
   "metadata": {},
   "source": [
    "### üü° Reflection 6: Dataset Properties\n",
    "\n",
    "1. Is the dataset balanced? (Do all digits appear roughly equally?)\n",
    "2. Why does this matter for training?\n",
    "3. What problems might arise with an imbalanced dataset?\n",
    "\n",
    "*Your thoughts:*\n",
    "\n",
    "1. **Balance**: Yes, it is **roughly balanced**. While not perfectly equal (Digit 1 has ~6700 samples vs Digit 5 has ~5400), no single digit dominates or is missing.\n",
    "\n",
    "2. **Importance**: It ensures the model treats all classes **fairly**. If 90% of data were \"1\"s, the model would just guess \"1\" every time and get 90% accuracy without learning anything!\n",
    "\n",
    "3. **Problems with Imbalance**: \n",
    "   - **Bias**: The model becomes biased towards the majority class.\n",
    "   - **Misleading Accuracy**: High accuracy but fails on the minority class (e.g., detecting rare diseases)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataloader",
   "metadata": {},
   "source": [
    "### üì¶ Creating Data Loaders\n",
    "\n",
    "Data loaders handle:\n",
    "- **Batching**: Processing multiple samples at once\n",
    "- **Shuffling**: Randomizing order (prevents overfitting)\n",
    "- **Parallel loading**: Faster data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_loaders",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîµ TASK 9: Create data loaders\n",
    "\n",
    "batch_size = 64  # Number of samples per batch\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,  # Shuffle training data\n",
    "    num_workers=2  # Parallel data loading\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,  # Don't shuffle test data\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Training batches: {len(train_loader)}\")\n",
    "print(f\"‚úÖ Test batches: {len(test_loader)}\")\n",
    "\n",
    "# Let's see what a batch looks like\n",
    "images, labels = next(iter(train_loader))\n",
    "print(f\"\\nBatch of images shape: {images.shape}\")\n",
    "print(f\"Batch of labels shape: {labels.shape}\")\n",
    "print(f\"First 10 labels in batch: {labels[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection7",
   "metadata": {},
   "source": [
    "### üü° Reflection 7: Understanding Batches\n",
    "\n",
    "1. Why do we use batches instead of processing one image at a time?\n",
    "2. What's the tradeoff between large and small batch sizes?\n",
    "3. Why shuffle training data but not test data?\n",
    "\n",
    "*Your reasoning:*\n",
    "\n",
    "1. **Efficiency & Stability**: Processing one image at a time is too slow and the gradients would be very \"noisy\" (erratic). Batches allow us to use **parallel computing** (GPU power) and get a more stable estimate of the gradient.\n",
    "\n",
    "2. **Tradeoff**:\n",
    "   - **Large Batches**: Faster training (better GPU usage), but requires more memory and can sometimes get stuck in \"sharp\" local minima (worse generalization).\n",
    "   - **Small Batches**: Slower, but the \"noise\" can actually help the model escape bad local minima and generalize better.\n",
    "\n",
    "3. **Shuffling**:\n",
    "   - **Train**: We shuffle to break any inherent order in the data (e.g., if all \"0\"s were first, the model would only learn \"0\"s for the first hour). It ensures every batch is a representative sample.\n",
    "   - **Test**: No need to shuffle! We just want to evaluate the model on all examples. Keeping the order is often helpful for debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "build_model",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Building Your Neural Network\n",
    "\n",
    "Now for the exciting part: **designing your model**!\n",
    "\n",
    "### Architecture Overview\n",
    "\n",
    "```\n",
    "Input (28√ó28 image) \n",
    "    ‚Üì\n",
    "Flatten to vector (784 values)\n",
    "    ‚Üì\n",
    "Hidden Layer 1 (128 neurons) + ReLU\n",
    "    ‚Üì\n",
    "Hidden Layer 2 (64 neurons) + ReLU\n",
    "    ‚Üì\n",
    "Output Layer (10 neurons, one per digit)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üü¢ TASK 10: Complete the neural network architecture\n",
    "\n",
    "class MNISTClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTClassifier, self).__init__()\n",
    "        \n",
    "        # Input: 28√ó28 = 784 pixels\n",
    "        # Output: 10 classes (digits 0-9)\n",
    "        \n",
    "        # YOUR CODE: Define three fully connected layers\n",
    "        # Layer 1: 784 ‚Üí 128\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        \n",
    "        # Layer 2: 128 ‚Üí 64\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        \n",
    "        # Layer 3: 64 ‚Üí 10\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, 1, 28, 28)\n",
    "        \n",
    "        # YOUR CODE: Flatten the image\n",
    "        # Hint: x.view(x.size(0), -1) keeps batch dimension\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # YOUR CODE: Pass through layers with ReLU activations\n",
    "        # Layer 1\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        # Layer 2\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        # Layer 3 (no activation - we'll use CrossEntropyLoss)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Create the model\n",
    "model = MNISTClassifier()\n",
    "print(model)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nüìä Total parameters: {total_params:,}\")\n",
    "print(f\"üìä Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test_model",
   "metadata": {},
   "source": [
    "### üß™ Test Your Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_forward",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if the model works with a dummy batch\n",
    "dummy_input = torch.randn(5, 1, 28, 28)  # Batch of 5 images\n",
    "print(f\"Input shape: {dummy_input.shape}\")\n",
    "\n",
    "try:\n",
    "    output = model(dummy_input)\n",
    "    print(f\"Output shape: {output.shape}\")\n",
    "    print(f\"‚úÖ Model architecture is correct!\")\n",
    "    \n",
    "    # Show what the untrained network outputs\n",
    "    print(f\"\\nRaw outputs (before training):\")\n",
    "    print(output[0])  # First sample\n",
    "    \n",
    "    # Apply softmax to see probabilities\n",
    "    probabilities = F.softmax(output[0], dim=0)\n",
    "    print(f\"\\nProbabilities for each digit (before training):\")\n",
    "    for digit in range(10):\n",
    "        print(f\"Digit {digit}: {probabilities[digit]:.2%}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"Check your forward() method!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection8",
   "metadata": {},
   "source": [
    "### üü° Reflection 8: Untrained Network Behavior\n",
    "\n",
    "Look at the probabilities above. Before training:\n",
    "1. How confident is the model about each digit?\n",
    "2. Why are the probabilities roughly equal?\n",
    "3. What will training do to these probabilities?\n",
    "\n",
    "*Your observations:*\n",
    "\n",
    "1. **Confidence**: It has **very low confidence** (about 10% for each digit). It is essentially guessing randomly.\n",
    "\n",
    "2. **Why Equal?**: The weights are initialized with **random small numbers**. Since the network hasn't learned any patterns yet, it treats every digit as equally likely. With 10 classes, random chance is 1/10 = 10%.\n",
    "\n",
    "3. **Training Effect**: Training will push the probability of the **correct** digit closer to **100%** (1.0) and push the others closer to **0%**. Ideally, we want to see something like [0.01, 0.98, 0.0, ...] for a digit \"1\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimizer_setup",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Setting Up Training\n",
    "\n",
    "Before we can train, we need:\n",
    "1. **Loss function**: Measures how wrong our predictions are\n",
    "2. **Optimizer**: Updates weights to reduce loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîµ TASK 11: Set up loss function and optimizer\n",
    "\n",
    "# Loss function for classification\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer - try different ones!\n",
    "# Option 1: SGD with momentum\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Option 2: Adam (often works better)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"‚úÖ Loss function: CrossEntropyLoss\")\n",
    "print(f\"‚úÖ Optimizer: {optimizer.__class__.__name__}\")\n",
    "print(f\"‚úÖ Learning rate: {optimizer.param_groups[0]['lr']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training_loop",
   "metadata": {},
   "source": [
    "## üèÉ Training Loop: Where the Magic Happens\n",
    "\n",
    "The training loop follows this pattern:\n",
    "\n",
    "```\n",
    "For each epoch:\n",
    "    For each batch:\n",
    "        1. Forward pass (make predictions)\n",
    "        2. Calculate loss (how wrong are we?)\n",
    "        3. Backward pass (compute gradients)\n",
    "        4. Update weights (take a step)\n",
    "        5. Zero gradients (prepare for next batch)\n",
    "```\n",
    "\n",
    "Let's implement this together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üü¢ TASK 12: Complete the training loop with your understanding\n",
    "\n",
    "def train_one_epoch(model, train_loader, criterion, optimizer, device='cpu'):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch\n",
    "    \n",
    "    Returns:\n",
    "        average_loss: Average loss over all batches\n",
    "        accuracy: Training accuracy\n",
    "    \"\"\"\n",
    "    model.train()  # Set model to training mode\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        # Move data to device (CPU or GPU)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # YOUR CODE: Step 1 - Forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # YOUR CODE: Step 2 - Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # YOUR CODE: Step 3 - Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # YOUR CODE: Step 4 - Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # YOUR CODE: Step 5 - Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Print progress every 100 batches\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f'  Batch [{batch_idx + 1}/{len(train_loader)}], '\n",
    "                  f'Loss: {loss.item():.4f}')\n",
    "    \n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "print(\"‚úÖ Training function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation",
   "metadata": {},
   "source": [
    "### üìä Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eval_function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, criterion, device='cpu'):\n",
    "    \"\"\"\n",
    "    Evaluate the model on test data\n",
    "    \n",
    "    Returns:\n",
    "        average_loss: Average loss over test set\n",
    "        accuracy: Test accuracy\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # Don't track gradients during evaluation\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Track statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    avg_loss = running_loss / len(test_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "print(\"‚úÖ Evaluation function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train_model",
   "metadata": {},
   "source": [
    "## üöÄ Let's Train!\n",
    "\n",
    "Time to see your neural network learn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "num_epochs = 5\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Training on: {device}\")\n",
    "print(f\"Number of epochs: {num_epochs}\")\n",
    "print(\"\\nStarting training...\\n\")\n",
    "\n",
    "# Track history\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "test_losses = []\n",
    "test_accs = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Evaluate\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "    \n",
    "    # Store history\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accs.append(test_acc)\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nEpoch Summary:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"  Test Loss:  {test_loss:.4f} | Test Acc:  {test_acc:.2f}%\")\n",
    "    print()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ Training Complete!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Final Test Accuracy: {test_accs[-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualize_training",
   "metadata": {},
   "source": [
    "### üìä Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss plot\n",
    "ax1.plot(train_losses, 'b-', label='Train Loss', linewidth=2)\n",
    "ax1.plot(test_losses, 'r-', label='Test Loss', linewidth=2)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training and Test Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "ax2.plot(train_accs, 'b-', label='Train Accuracy', linewidth=2)\n",
    "ax2.plot(test_accs, 'r-', label='Test Accuracy', linewidth=2)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('Training and Test Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection9",
   "metadata": {},
   "source": [
    "### üü° Reflection 9: Analyzing Training Curves\n",
    "\n",
    "Look at the plots above:\n",
    "1. How did the loss change over epochs? What does this tell you?\n",
    "2. Is there a gap between train and test accuracy? What does this mean?\n",
    "3. Did the model overfit or underfit? How can you tell?\n",
    "4. What could you do to improve performance?\n",
    "\n",
    "*Your analysis:*\n",
    "\n",
    "1. **Loss Changes**: Both training and test loss decreased significantly, which means the model is effectively learning from the data. The training loss dropped much faster and lower (from ~0.27 to ~0.05) than the test loss (from ~0.13 to ~0.08).\n",
    "\n",
    "2. **Accuracy Gap**: Yes, there is a gap. The training accuracy (~98.5%) is higher than the test accuracy (~97.5%). This means the model is slightly better at recognizing images it has already seen compared to new, unseen images.\n",
    "\n",
    "3. **Overfitting**: The model is starting to **overfit**. We can tell because the training loss continues to dive steeply while the test loss has flattened out and stopped improving. The widening gap between the training and test curves is a classic sign that the model is memorizing the training data rather than just generalizing.\n",
    "\n",
    "4. **Improvements**: To fix this, we could:\n",
    "   - Add **Dropout** layers to randomly disable neurons during training.\n",
    "   - Use **Data Augmentation** (rotate, shift, or zoom images) to create more variety.\n",
    "   - Use **Early Stopping** to stop training before the test loss starts to get worse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "predictions",
   "metadata": {},
   "source": [
    "## üîÆ See Your Model in Action!\n",
    "\n",
    "Let's visualize what your trained network can do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize_predictions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of test images\n",
    "model.eval()\n",
    "images, labels = next(iter(test_loader))\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "# Get predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(images)\n",
    "    probabilities = F.softmax(outputs, dim=1)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Move back to CPU for plotting\n",
    "images = images.cpu()\n",
    "labels = labels.cpu()\n",
    "predicted = predicted.cpu()\n",
    "probabilities = probabilities.cpu()\n",
    "\n",
    "# Visualize predictions\n",
    "fig, axes = plt.subplots(3, 6, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(18):\n",
    "    img = images[i].squeeze().numpy()\n",
    "    true_label = labels[i].item()\n",
    "    pred_label = predicted[i].item()\n",
    "    confidence = probabilities[i][pred_label].item()\n",
    "    \n",
    "    axes[i].imshow(img, cmap='gray')\n",
    "    \n",
    "    # Color: green if correct, red if wrong\n",
    "    color = 'green' if true_label == pred_label else 'red'\n",
    "    axes[i].set_title(\n",
    "        f'True: {true_label}\\nPred: {pred_label} ({confidence:.1%})',\n",
    "        color=color,\n",
    "        fontsize=10\n",
    "    )\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Model Predictions (Green = Correct, Red = Wrong)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confusion_matrix",
   "metadata": {},
   "source": [
    "### üìä Confusion Matrix: Where Does the Model Struggle?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compute_confusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Get all predictions\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix: Where Does the Model Make Mistakes?')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find most confused pairs\n",
    "print(\"\\nMost Common Confusions:\")\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i != j and cm[i, j] > 50:  # Threshold for \"common\"\n",
    "            print(f\"  {i} misclassified as {j}: {cm[i, j]} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection10",
   "metadata": {},
   "source": [
    "### üü° Reflection 10: Understanding Errors\n",
    "\n",
    "Look at the confusion matrix:\n",
    "1. Which digits does the model confuse most often?\n",
    "2. Why might these specific digits be confused?\n",
    "3. How could you improve the model to reduce these errors?\n",
    "\n",
    "*Your insights:*\n",
    "\n",
    "1. **Common Confusions**: The model struggles most with:\n",
    "   - **3 vs 5** (17 errors): This is the biggest source of confusion.\n",
    "   - **6 vs 5** (13 errors)\n",
    "   - **9 vs 5** (12 errors)\n",
    "   - **7 vs 2** (11 errors)\n",
    "\n",
    "2. **Why?**: These digits share similar structural features:\n",
    "   - **3, 5, 6, 9**: All have curved loops. If a 3 is written with a straight top, it looks like a 5. A messy 6 or 9 can also look like a 5 if the loop isn't clear.\n",
    "   - **7 vs 2**: Both use diagonal strokes. A 7 with a hooked top can look like a 2, or a 2 with a sharp corner can look like a 7.\n",
    "\n",
    "3. **How to Improve**:\n",
    "   - **Data Augmentation**: Apply small rotations or distortions to help the model learn to handle messy handwriting.\n",
    "   - **CNNs**: Switch to a Convolutional Neural Network, which is much better at detecting local shapes (loops, edges) than our simple linear model.\n",
    "   - **Analyze Errors**: Specifically look at the images the model got wrong to understand if they are truly ambiguous (even humans might get them wrong)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenges",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üî¥ Advanced Challenges: Push Your Limits!\n",
    "\n",
    "You've mastered the basics. Now it's time to explore!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenge1_desc",
   "metadata": {},
   "source": [
    "## üî¥ Challenge 1: Experiment with Architectures\n",
    "\n",
    "**Goal**: Design a better model\n",
    "\n",
    "Try:\n",
    "- Adding more layers\n",
    "- Changing layer sizes\n",
    "- Adding dropout (prevents overfitting)\n",
    "- Adding batch normalization\n",
    "\n",
    "**Target**: Beat 97% test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenge1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¥ YOUR CHALLENGE: Design your own architecture\n",
    "\n",
    "class ImprovedClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImprovedClassifier, self).__init__()\n",
    "        \n",
    "        # YOUR DESIGN HERE\n",
    "        # Ideas:\n",
    "        # - More layers\n",
    "        # - Dropout: nn.Dropout(0.5)\n",
    "        # - Batch norm: nn.BatchNorm1d(size)\n",
    "        # - Different activation functions\n",
    "        \n",
    "        # 1. Input Layer (784 -> 512)\n",
    "        self.fc1 = nn.Linear(784, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)  # Batch Norm for stability\n",
    "        \n",
    "        # 2. Hidden Layer (512 -> 256)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        # 3. Hidden Layer (256 -> 128)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        # 4. Output Layer (128 -> 10)\n",
    "        self.fc4 = nn.Linear(128, 10)\n",
    "        \n",
    "        # Dropout to prevent overfitting\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # YOUR FORWARD PASS HERE\n",
    "        # Flatten input\n",
    "        x = x.view(-1, 784)\n",
    "        \n",
    "        # Layer 1: Linear -> BN -> ReLU -> Dropout\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Layer 2: Linear -> BN -> ReLU -> Dropout\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Layer 3: Linear -> BN -> ReLU -> Dropout\n",
    "        x = self.fc3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Output Layer: Linear\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# Train and compare!\n",
    "print(\"üöÄ Training Improved Model...\")\n",
    "improved_model = ImprovedClassifier().to(device)\n",
    "optimizer_improved = torch.optim.Adam(improved_model.parameters(), lr=0.001)\n",
    "\n",
    "# Train loop for improved model\n",
    "improved_train_losses = []\n",
    "improved_test_accs = []\n",
    "\n",
    "for epoch in range(5):  # Train for 5 epochs\n",
    "    train_loss, train_acc = train_one_epoch(improved_model, train_loader, criterion, optimizer_improved, device)\n",
    "    test_loss, test_acc = evaluate(improved_model, test_loader, criterion, device)\n",
    "    \n",
    "    improved_train_losses.append(train_loss)\n",
    "    improved_test_accs.append(test_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Test Acc={test_acc:.2f}%\")\n",
    "\n",
    "print(f\"\\nüèÜ Final Test Accuracy: {improved_test_accs[-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenge2_desc",
   "metadata": {},
   "source": [
    "## üî¥ Challenge 2: Hyperparameter Tuning\n",
    "\n",
    "**Goal**: Find the best hyperparameters\n",
    "\n",
    "Experiment with:\n",
    "- Learning rates: [0.1, 0.01, 0.001, 0.0001]\n",
    "- Batch sizes: [32, 64, 128, 256]\n",
    "- Optimizers: SGD, Adam, RMSprop\n",
    "- Number of epochs\n",
    "\n",
    "**Document** what you try and what works best!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenge2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¥ YOUR CHALLENGE: Systematic hyperparameter search\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create a table to track results\n",
    "results = []\n",
    "\n",
    "# Example experiment\n",
    "for lr in [0.01, 0.001, 0.0001]:\n",
    "    for batch_size in [32, 64, 128]:\n",
    "        print(f\"\\nTrying: lr={lr}, batch_size={batch_size}\")\n",
    "        \n",
    "        # YOUR CODE: Create model, train, evaluate\n",
    "        # 1. Prepare Data Loader\n",
    "        temp_train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        # 2. Create Model\n",
    "        model = MNISTClassifier().to(device)\n",
    "        \n",
    "        # 3. Optimizer (Using Adam)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "        # 4. Train (1 epoch for speed)\n",
    "        train_one_epoch(model, temp_train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        # 5. Evaluate\n",
    "        _, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "        \n",
    "        # Record results\n",
    "        results.append({\n",
    "            'Learning Rate': lr,\n",
    "            'Batch Size': batch_size,\n",
    "            'Test Accuracy': test_acc\n",
    "        })\n",
    "\n",
    "# Visualize results\n",
    "df_results = pd.DataFrame(results)\n",
    "display(df_results.sort_values(by='Test Accuracy', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenge3_desc",
   "metadata": {},
   "source": [
    "## üî¥ Challenge 3: Visualize What the Network Learns\n",
    "\n",
    "**Goal**: Understand what features the network has learned\n",
    "\n",
    "Visualize:\n",
    "1. First layer weights as images\n",
    "2. Activation patterns for different digits\n",
    "3. Which neurons activate for which digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenge3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¥ YOUR CHALLENGE: Visualize learned features\n",
    "\n",
    "# Hint: model.fc1.weight has shape (128, 784)\n",
    "# Each row is a \"filter\" - reshape to 28√ó28 and visualize\n",
    "\n",
    "weights = model.fc1.weight.data.cpu()\n",
    "print(f\"First layer weights shape: {weights.shape}\")\n",
    "\n",
    "# Visualize first 25 filters\n",
    "fig, axes = plt.subplots(5, 5, figsize=(10, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(25):\n",
    "    # YOUR CODE: Reshape weight to 28√ó28 and plot\n",
    "    weight_img = weights[i].view(28, 28)\n",
    "    axes[i].imshow(weight_img, cmap='viridis')\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(f'Neuron {i}')\n",
    "\n",
    "plt.suptitle('What the First Layer Learned')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 2. Visualize Activation Patterns for Different Digits\n",
    "print(\"\\n2. Visualizing Activation Patterns for Different Digits...\")\n",
    "\n",
    "# Get one sample of each digit\n",
    "digit_samples = {}\n",
    "found_digits = 0\n",
    "for img, label in test_dataset:\n",
    "    if label not in digit_samples:\n",
    "        digit_samples[label] = img\n",
    "        found_digits += 1\n",
    "    if found_digits == 10:\n",
    "        break\n",
    "\n",
    "# Sort by digit\n",
    "sorted_digits = sorted(digit_samples.keys())\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, digit in enumerate(sorted_digits):\n",
    "        img = digit_samples[digit].to(device)\n",
    "        # Forward pass up to first layer\n",
    "        x = img.view(-1, 784)\n",
    "        activation = F.relu(model.fc1(x))\n",
    "        \n",
    "        # Plot activation as a heatmap/bar\n",
    "        # Reshaping to 8x16 for compact visualization of 128 neurons (or adjust if size differs)\n",
    "        num_neurons = activation.shape[1]\n",
    "        rows = int(num_neurons**0.5)\n",
    "        cols = num_neurons // rows\n",
    "        if rows * cols != num_neurons: # Fallback if not perfect square/rectangle\n",
    "            rows, cols = 1, num_neurons\n",
    "            \n",
    "        act_img = activation.cpu().view(rows, cols)\n",
    "        \n",
    "        axes[i].imshow(act_img, cmap='hot', interpolation='nearest')\n",
    "        axes[i].set_title(f'Digit {digit} Activations')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Layer 1 Activations for Each Digit (Brighter = Higher Activation)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Average Neuron Activation per Digit\n",
    "print(\"\\n3. Which neurons activate for which digits? (Average Activation)\")\n",
    "\n",
    "# Compute average activation per neuron for each digit class\n",
    "num_neurons = model.fc1.out_features\n",
    "neuron_activations = torch.zeros(10, num_neurons).to(device)\n",
    "\n",
    "# Use a subset of test data for speed\n",
    "subset_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "images, labels = next(iter(subset_loader)) # Get first batch of 1000 images\n",
    "\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    x = images.view(-1, 784)\n",
    "    activations = F.relu(model.fc1(x))\n",
    "    \n",
    "    for digit in range(10):\n",
    "        mask = (labels == digit)\n",
    "        if mask.sum() > 0:\n",
    "            digit_activations = activations[mask]\n",
    "            neuron_activations[digit] = digit_activations.mean(dim=0)\n",
    "\n",
    "# Plot Heatmap\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.imshow(neuron_activations.cpu(), cmap='hot', aspect='auto')\n",
    "plt.colorbar(label='Average Activation')\n",
    "plt.xlabel(f'Neuron Index (0-{num_neurons-1})')\n",
    "plt.ylabel('Digit Class (0-9)')\n",
    "plt.title('Average Neuron Activation by Digit Class')\n",
    "plt.yticks(range(10))\n",
    "plt.show()\n",
    "\n",
    "# Find most active neuron for each digit\n",
    "print(\"\\nTop neuron for each digit:\")\n",
    "for digit in range(10):\n",
    "    top_neuron = neuron_activations[digit].argmax().item()\n",
    "    print(f\"Digit {digit}: Neuron {top_neuron}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final_reflection",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üéì Final Reflection: Your Learning Journey\n",
    "\n",
    "Congratulations! You've come a long way. Take a moment to reflect on what you've learned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final_questions",
   "metadata": {},
   "source": [
    "### üü° Final Reflection Questions\n",
    "\n",
    "1. **Biggest Insight**: What was your biggest \"aha!\" moment in this lab?\n",
    "\n",
    "*Your answer:*\n",
    "**The confusion matrix was my biggest \"aha!\" moment.** It was powerful to clearly identify exactly where the model makes mistakes (e.g., confusing 4s with 9s) rather than just looking at a single accuracy number. This diagnostic tool gave me a much deeper understanding of the model's behavior.\n",
    "\n",
    "2. **Conceptual Understanding**: In your own words, explain how neural networks learn.\n",
    "\n",
    "*Your explanation:*\n",
    "**Learning is a 4-step loop:**\n",
    "1. **Guess (Forward)**: The network takes input and produces a prediction.\n",
    "2. **Measure Error (Loss)**: It compares the prediction to the truth (e.g., \"I said 7, but it's 1\").\n",
    "3. **Blame (Backward)**: Autograd calculates gradients to see which weights contributed to the error.\n",
    "4. **Update (Optimizer)**: The optimizer nudges the weights in the opposite direction of the gradient to reduce error next time.\n",
    "\n",
    "3. **Practical Skills**: What practical skills did you gain that you could apply to other problems?\n",
    "\n",
    "*Your list:*\n",
    "- **PyTorch Mechanics**: Creating tensors, using `requires_grad`, and `.to(device)`.\n",
    "- **Model Building**: Subclassing `nn.Module` and defining layers.\n",
    "- **Training Loops**: Writing the standard forward-loss-backward-step cycle.\n",
    "- **Diagnostics**: Using confusion matrices and loss curves to debug performance.\n",
    "- **Data Handling**: Using `DataLoader` and batches effectively.\n",
    "\n",
    "4. **Challenges Faced**: What was most challenging? How did you overcome it?\n",
    "\n",
    "*Your experience:*\n",
    "**Managing tensor shapes was tricky.** Flattening the 28x28 images to 784 vectors for the linear layers caused some dimension mismatch errors initially. I overcame this by constantly printing `x.shape` inside the forward method to debug and understand exactly how data flows through the network.\n",
    "\n",
    "5. **Next Steps**: What would you like to learn next in deep learning?\n",
    "\n",
    "*Your goals:*\n",
    "I want to learn about **Convolutional Neural Networks (CNNs)**. Since we treated images as flat vectors here, we lost spatial information. I'm curious to see how CNNs can handle images better by preserving their 2D structure. I'd also like to try this on color images like CIFAR-10.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## üìö What You've Accomplished\n",
    "\n",
    "‚úÖ **Mastered Tensors**: Created and manipulated multi-dimensional data\n",
    "\n",
    "‚úÖ **Understood Autograd**: Discovered automatic differentiation\n",
    "\n",
    "‚úÖ **Implemented Gradient Descent**: Saw optimization in action\n",
    "\n",
    "‚úÖ **Built a Neural Network**: From scratch!\n",
    "\n",
    "‚úÖ **Trained on Real Data**: MNIST digit classification\n",
    "\n",
    "‚úÖ **Evaluated Performance**: Analyzed what works and what doesn't\n",
    "\n",
    "‚úÖ **Explored Advanced Concepts**: Through challenges and experiments\n",
    "\n",
    "\n",
    "## üåü Remember\n",
    "\n",
    "> \"The only way to learn deep learning is by doing deep learning.\"\n",
    "\n",
    "Keep experimenting, keep learning, keep building!\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Learning! üéâ**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d159e1c3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
